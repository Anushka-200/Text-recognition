{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e87d93e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BN86C3~1.KUL\\AppData\\Local\\Temp/ipykernel_10704/3303466977.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextnsn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'path_img'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m   \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[0mdim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "#Getting dimension, channels & extension of all images in train dataframe\n",
    "\n",
    "dim, channel, extnsn = [], [], []\n",
    "for path in df_train['path_img'].values:\n",
    "  img = cv2.imread(path)\n",
    "  dim.append(img.shape[:2])\n",
    "  channel.append(img.shape[2])\n",
    "  extnsn.append(path.split('.')[-1])\n",
    "print('Dimension of all images:',set(dim))\n",
    "print('No. channels of all images:',set(channel))\n",
    "print('Extesions of all images:',set(extnsn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d591c587",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BN86C3~1.KUL\\AppData\\Local\\Temp/ipykernel_10704/3193962198.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Getting dimension, channels & extension of all images in test dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextnsn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'path_img'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m   \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mdim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "#Getting dimension, channels & extension of all images in test dataframe\n",
    "dim, channel, extnsn = [], [], []\n",
    "for path in df_test['path_img'].values:\n",
    "  img = cv2.imread(path)\n",
    "  dim.append(img.shape[:2])\n",
    "  channel.append(img.shape[2])\n",
    "  extnsn.append(path.split('.')[-1])\n",
    "print('Dimension of all images:',set(dim))\n",
    "print('No. channels of all images:',set(channel))\n",
    "print('Extesions of all images:',set(extnsn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d577f04",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BN86C3~1.KUL\\AppData\\Local\\Temp/ipykernel_10704/4199208968.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvgg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'block5_pool'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUpSampling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bilinear'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'channels_last'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'resize_1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'block4_pool'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "vgg = tf.keras.applications.VGG16(input_shape=(512,512,3),include_top=False,weights='imagenet')\n",
    "x = vgg.get_layer('block5_pool').output\n",
    "\n",
    "x = tf.keras.layers.UpSampling2D(size=(2,2),interpolation='bilinear',data_format='channels_last',name='resize_1')(x)\n",
    "x = tf.keras.layers.concatenate([x,vgg.get_layer('block4_pool').output], axis=3)\n",
    "x = tf.keras.layers.Conv2D(256, (1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "x = tf.keras.layers.UpSampling2D(size=(2,2),interpolation='bilinear',data_format='channels_last',name='resize_2')(x)\n",
    "x = tf.keras.layers.concatenate([x, vgg.get_layer('block3_pool').output], axis=3)\n",
    "x = tf.keras.layers.Conv2D(128, (1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "x = tf.keras.layers.UpSampling2D(size=(2,2),interpolation='bilinear',data_format='channels_last',name='resize_3')(x)\n",
    "x = tf.keras.layers.concatenate([x, vgg.get_layer('block2_pool').output], axis=3)\n",
    "x = tf.keras.layers.Conv2D(64, (1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32,kernel_size=3, strides=1,padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.UpSampling2D(size=(4,4),interpolation='bilinear',data_format='channels_last',name='extra')(x)\n",
    "\n",
    "\n",
    "pred_score_map = tf.keras.layers.Conv2D(1, (1, 1), activation=tf.nn.sigmoid, name='pred_score_map',padding='same')(x)\n",
    "rbox_geo_map = tf.keras.layers.Conv2D(4, (1, 1), activation=tf.nn.sigmoid, name='rbox_geo_map')(x)\n",
    "rbox_geo_map = tf.keras.layers.Lambda(lambda x: x * 512)(rbox_geo_map)\n",
    "angle_map = tf.keras.layers.Conv2D(1, (1, 1), activation=tf.nn.sigmoid, name='rbox_angle_map')(x)\n",
    "angle_map = tf.keras.layers.Lambda(lambda x: (x - 0.5) * np.pi / 2)(angle_map)\n",
    "output = tf.keras.layers.concatenate([pred_score_map,rbox_geo_map, angle_map], axis=3, name='pred_map')\n",
    "\n",
    "\n",
    "model_vgg = tf.keras.models.Model(inputs=vgg.input, outputs= output,name='EAST')\n",
    "for layers in vgg.layers:\n",
    "  layers.trainable=False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ddf897",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BN86C3~1.KUL\\AppData\\Local\\Temp/ipykernel_10704/1810514215.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'conv5_block3_out'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUpSampling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bilinear'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'channels_last'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'resize_1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "resnet = tf.keras.applications.ResNet50(input_shape=(512, 512, 3), weights='imagenet', include_top=False)\n",
    "tf.keras.backend.clear_session()\n",
    "x = resnet.get_layer('conv5_block3_out').output\n",
    "\n",
    "x = tf.keras.layers.UpSampling2D(size=(2,2),interpolation='bilinear',data_format='channels_last',name='resize_1')(x)\n",
    "x = tf.keras.layers.concatenate([x, resnet.get_layer('conv4_block6_out').output], axis=3)\n",
    "x = tf.keras.layers.Conv2D(128, (1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "x = tf.keras.layers.UpSampling2D(size=(2,2),interpolation='bilinear',data_format='channels_last',name='resize_2')(x)\n",
    "x = tf.keras.layers.concatenate([x, resnet.get_layer('conv3_block4_out').output], axis=3)\n",
    "x = tf.keras.layers.Conv2D(64, (1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "x = tf.keras.layers.UpSampling2D(size=(2,2),interpolation='bilinear',data_format='channels_last',name='resize_3')(x)\n",
    "x = tf.keras.layers.concatenate([x, resnet.get_layer('conv2_block3_out').output], axis=3)\n",
    "x = tf.keras.layers.Conv2D(32, (1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "\n",
    "pred_score_map = tf.keras.layers.Conv2D(1, (1, 1), activation=tf.nn.sigmoid, name='pred_score_map')(x)\n",
    "rbox_geo_map = tf.keras.layers.Conv2D(4, (1, 1), activation=tf.nn.sigmoid, name='rbox_geo_map')(x)\n",
    "angle_map = tf.keras.layers.Conv2D(1, (1, 1), activation=tf.nn.sigmoid, name='rbox_angle_map')(x)\n",
    "angle_map = tf.keras.layers.Lambda(lambda x: (x - 0.5) * np.pi / 2)(angle_map)\n",
    "output = tf.keras.layers.concatenate([pred_score_map,rbox_geo_map, angle_map], axis=3, name='pred_map')\n",
    "\n",
    "\n",
    "model = tf.keras.models.Model(inputs=resnet.input, outputs= output,name='EAST')\n",
    "for layers in resnet.layers:\n",
    "  layers.trainable=False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4f75d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is dice coefficient loss used to classify point as text and non text region \n",
    "def dice_coefficient(y_true_cls, y_pred_cls,training_mask):\n",
    "    '''\n",
    "    dice loss\n",
    "    :param y_true_cls:\n",
    "    :param y_pred_cls:\n",
    "    :param training_mask:x\n",
    "    :return:\n",
    "    '''\n",
    "    eps = 10**-6\n",
    "    intersection = tf.reduce_sum(y_true_cls * y_pred_cls * training_mask)\n",
    "    \n",
    "    union = tf.reduce_sum(y_true_cls * training_mask) + tf.reduce_sum(y_pred_cls * training_mask) + eps\n",
    "    loss = 1. - (2 * intersection / union)\n",
    "    return loss\n",
    "\n",
    "def rbox_loss(y_true_cls,y_true_geo,y_pred_geo,training_mask):\n",
    "  # d1 -> top, d2->right, d3->bottom, d4->left\n",
    "  d1_gt, d2_gt, d3_gt, d4_gt, theta_gt = tf.split(value=y_true_geo, num_or_size_splits=5, axis=3)\n",
    "  d1_pred, d2_pred, d3_pred, d4_pred, theta_pred = tf.split(value=y_pred_geo, num_or_size_splits=5, axis=3)\n",
    "\n",
    "  area_gt = (d1_gt + d3_gt) * (d2_gt + d4_gt)\n",
    "  area_pred = (d1_pred + d3_pred) * (d2_pred + d4_pred)\n",
    "  w_union = tf.minimum(d2_gt, d2_pred) + tf.minimum(d4_gt, d4_pred)\n",
    "  h_union = tf.minimum(d1_gt, d1_pred) + tf.minimum(d3_gt, d3_pred)\n",
    "  area_intersect = w_union * h_union\n",
    "  area_union = area_gt + area_pred - area_intersect\n",
    "\n",
    "  L_AABB = -tf.math.log((area_intersect + 1.0) / (area_union + 1.0))\n",
    "  L_theta = 1 - tf.cos(theta_pred - theta_gt)\n",
    "\n",
    "  L_g = L_AABB +  50*L_theta\n",
    "  L_g=tf.squeeze(L_g,axis=3)\n",
    "\n",
    "  return tf.reduce_mean(L_g * y_true_cls * training_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44aec50a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BN86C3~1.KUL\\AppData\\Local\\Temp/ipykernel_10704/2321466382.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#This class contains complete loss we have used for text Detection Branch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mtotal_Loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAUTO\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Loss_layer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m       \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_Loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "#This class contains complete loss we have used for text Detection Branch\n",
    "class total_Loss(tf.keras.losses.Loss):\n",
    "  def __init__(self, from_logits=False,reduction=tf.keras.losses.Reduction.AUTO,name='Loss_layer'):\n",
    "      super(total_Loss, self).__init__(reduction=reduction, name=name)\n",
    "  def call(self, y_true, y_pred):\n",
    "    \n",
    "    #Getting geo_map and score_maps\n",
    "    y_true_cls=y_true[:,:,:,0]\n",
    "    y_pred_cls=y_pred[:,:,:,0]\n",
    "    y_pred_geo=y_pred[:,:,:,1:6]\n",
    "    y_true_geo=y_true[:,:,:,1:6]\n",
    "    training_mask=y_true[:,:,:,6]\n",
    "    \n",
    "    #1. Dice Loss\n",
    "    dice_loss = dice_coefficient(y_true_cls, y_pred_cls, training_mask)\n",
    "    # we scale classification loss by factor of 0.01 to match the iou loss part\n",
    "    dice_loss *=0.01\n",
    "\n",
    "    rbox_loss_ = rbox_loss(y_true_cls,y_true_geo,y_pred_geo,training_mask)\n",
    "    \n",
    "     \n",
    "    return 100*(rbox_loss_ + dice_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "502e3143",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_vgg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BN86C3~1.KUL\\AppData\\Local\\Temp/ipykernel_10704/159002793.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_vgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mamsgrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtotal_Loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model_vgg' is not defined"
     ]
    }
   ],
   "source": [
    "model_vgg.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,amsgrad=True),loss= total_Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4719736",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BN86C3~1.KUL\\AppData\\Local\\Temp/ipykernel_10704/4212317295.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mamsgrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_Loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,amsgrad=True),loss=total_Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e1329ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These Are Function that will be used while converting geo_maps to score_maps and returns bounding boxes for image after nms\n",
    "\n",
    "def sort_poly(p):\n",
    "  min_axis = np.argmin(np.sum(p, axis=1))\n",
    "  p = p[[min_axis, (min_axis+1)%4, (min_axis+2)%4, (min_axis+3)%4]]\n",
    "  if abs(p[0, 0] - p[1, 0]) > abs(p[0, 1] - p[1, 1]):\n",
    "    return p\n",
    "  else:\n",
    "    return p[[0, 3, 2, 1]]\n",
    "def intersection(g, p):\n",
    "    g = Polygon(g[:8].reshape((4, 2)))\n",
    "    p = Polygon(p[:8].reshape((4, 2)))\n",
    "    if not g.is_valid or not p.is_valid:\n",
    "        return 0\n",
    "    inter = Polygon(g).intersection(Polygon(p)).area\n",
    "    union = g.area + p.area - inter\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return inter/union\n",
    "\n",
    "\n",
    "def weighted_merge(g, p):\n",
    "    g[:8] = (g[8] * g[:8] + p[8] * p[:8])/(g[8] + p[8])\n",
    "    g[8] = (g[8] + p[8])\n",
    "    return g\n",
    "\n",
    "\n",
    "def standard_nms(S, thres):\n",
    "    order = np.argsort(S[:, 8])[::-1]\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        ovr = np.array([intersection(S[i], S[t]) for t in order[1:]])\n",
    "\n",
    "        inds = np.where(ovr <= thres)[0]\n",
    "        order = order[inds+1]\n",
    "\n",
    "    return S[keep]\n",
    "\n",
    "\n",
    "def nms_locality(polys, thres=0.3):\n",
    "    '''\n",
    "    :param polys: a N*9 numpy array. first 8 coordinates, then prob\n",
    "    :return: boxes after nms\n",
    "    '''\n",
    "    S = []\n",
    "    p = None\n",
    "  \n",
    "    for g in polys:\n",
    "        if p is not None and intersection(g, p) > thres:\n",
    "        \n",
    "            p = weighted_merge(g, p)\n",
    "        else:\n",
    "            if p is not None:\n",
    "                S.append(p)\n",
    "            p = g\n",
    "  \n",
    "    if p is not None:\n",
    "        S.append(p)\n",
    "\n",
    "    if len(S) == 0:\n",
    "        return np.array([])\n",
    "    \n",
    "    return standard_nms(np.array(S), thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37e5b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference pipeline function used for generating predicted bounding boxes on image for text detection\n",
    "def inferencePipeline(img,model):\n",
    "  \n",
    "  start_time=time.time()\n",
    "  \n",
    "  #1.Text Detection\n",
    "  img=cv2.resize(img,(512,512))\n",
    "  ii=model.predict(np.expand_dims(img,axis=0))\n",
    "  score_map=ii[0][:,:,0]\n",
    "  geo_map=ii[0][:,:,1:]\n",
    "  print(\"Shape of Score Map\",score_map.shape)\n",
    "  print(\"Shape of Geo Map\",geo_map.shape)\n",
    "\n",
    "  for ind in [0,1,2,3,4]:\n",
    "    geo_map[:,:,ind]*=score_map\n",
    "\n",
    "  #2.ROI Rotate  \n",
    "  score_map_thresh=0.5\n",
    "  box_thresh=0.1 \n",
    "  nms_thres=0.2\n",
    "  if len(score_map.shape) == 4:\n",
    "    score_map = score_map[0, :, :, 0]\n",
    "    geo_map = geo_map[0, :, :, :]\n",
    "\n",
    "  # filter the score map\n",
    "  xy_text = np.argwhere(score_map > score_map_thresh)\n",
    "\n",
    "  # sort the text boxes via the y axis\n",
    "  xy_text = xy_text[np.argsort(xy_text[:, 0])]\n",
    "\n",
    "  # restore\n",
    "  text_box_restored = restore_rectangle(xy_text[:, ::-1], geo_map[xy_text[:, 0], xy_text[:, 1], :]) # N*4*2\n",
    "  boxes = np.zeros((text_box_restored.shape[0], 9), dtype=np.float32)\n",
    "  boxes[:, :8] = text_box_restored.reshape((-1, 8))\n",
    "  boxes[:, 8] = score_map[xy_text[:, 0], xy_text[:, 1]]\n",
    "  print(\"Boxes Shape\",boxes.shape)\n",
    "  boxes = nms_locality(boxes.astype(np.float64), nms_thres)\n",
    "\n",
    "  \n",
    "  # here we filter some low score boxes by the average score map, this is different from the orginal paper\n",
    "  for i, box in enumerate(boxes):\n",
    "    mask = np.zeros_like(score_map, dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, box[:8].reshape((-1, 4, 2)).astype(np.int32), 1)\n",
    "    boxes[i, 8] = cv2.mean(score_map, mask)[0]\n",
    "  \n",
    "    if i==4:\n",
    "      break\n",
    "  if len(boxes)>0:\n",
    "    boxes = boxes[boxes[:, 8] > box_thresh]\n",
    "  boxes[:,:8:2] = np.clip(boxes[:,:8:2], 0, 512 - 1)\n",
    "  boxes[:,1:8:2] = np.clip(boxes[:,1:8:2], 0, 512 - 1)  \n",
    "  res = []\n",
    "  result = []\n",
    "  if len(boxes)>0:\n",
    "\n",
    "    for box in boxes:\n",
    "      box_ =  box[:8].reshape((4, 2))\n",
    "      if np.linalg.norm(box_[0] - box_[1]) < 8 or np.linalg.norm(box_[3]-box_[0]) < 8:\n",
    "        continue\n",
    "      result.append(box_)\n",
    "  res.append(np.array(result, np.float32))   \n",
    "\n",
    "  box_index = []\n",
    "  brotateParas = []\n",
    "  filter_bsharedFeatures = []\n",
    "  for i in range(len(res)):\n",
    "    rotateParas = []\n",
    "    rboxes=res[i]\n",
    "    txt=[]\n",
    "    for j, rbox in enumerate(rboxes):\n",
    "      para = restore_roiRotatePara(rbox)\n",
    "      if para and min(para[1][2:]) > 8:\n",
    "        rotateParas.append(para)\n",
    "        box_index.append((i, j))\n",
    "    pts=[]   \n",
    "    \n",
    "    \n",
    "    #3. Text Recognition (From boxes given by Text Detection+ROI Rotate) \n",
    "    \n",
    "  if len(rotateParas) > 0:\n",
    "      \n",
    "      for num in range(len(rotateParas)):\n",
    "        text=\"\"\n",
    "        out=rotateParas[num][0]\n",
    "        crop=rotateParas[num][1]\n",
    "        points=np.array([[out[0],out[1]],[out[0]+out[2],out[1]],[out[0]+out[2],out[1]+out[3]],[out[0],out[1]+out[3]]])\n",
    "        pts.append(points)\n",
    "    \n",
    "    # 4. Labeling detected and Recognized Text in Image\n",
    "    \n",
    "  for i in range(len(pts)):\n",
    "      cv2.polylines(img,[pts[i]],isClosed=True,color=(0,255,0),thickness=2)\n",
    "      #cv2.putText(img,txt[i],(pts[i][0][0],pts[i][0][1]),cv2.FONT_HERSHEY_SIMPLEX,0.8, (0, 255, 0), 3)\n",
    "  end_time=time.time()\n",
    "  print(\"Time Taken By Pipeline=\"+str(end_time-start_time)+\" seconds\") \n",
    "  return img   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71a9e31f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BN86C3~1.KUL\\AppData\\Local\\Temp/ipykernel_10704/1267824498.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Orignal model size=\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'east_resnet.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1e+6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"MB\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Dynamic Post Training Quantization model size=\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dynamic_east.tflite'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1e+6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"MB\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Float16 Post Training Quantization model size=\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'east_float16.tflite'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1e+6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"MB\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Orignal model size=\",(os.path.getsize('east_resnet.h5')/1e+6),\"MB\")\n",
    "print(\"Dynamic Post Training Quantization model size=\",os.path.getsize('dynamic_east.tflite')/1e+6,\"MB\")\n",
    "print(\"Float16 Post Training Quantization model size=\",os.path.getsize('east_float16.tflite')/1e+6,\"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d766ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
